{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f7a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import modf\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "from estimation.config import get_default_configuration\n",
    "from estimation.coordinates import get_coordinates\n",
    "from estimation.connections import get_connections\n",
    "from estimation.estimators import estimate\n",
    "from estimation.renderers import draw\n",
    "\n",
    "from train_singlenet_mobilenetv3 import register_tf_netbuilder_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f476d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"resources/sample2.mp4\"\n",
    "output_video = \"sample12_out2.mp4\"\n",
    "create_model_fn = \"create_openpose_singlenet\"\n",
    "weights_path = \"output_singlenet/0620_epoch300/openpose_singlenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90205e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trun_on_camera(video=0, is_resize=False):\n",
    "    if is_resize == False:\n",
    "        cam = cv2.VideoCapture(video)\n",
    "        if not cam.isOpened():\n",
    "            print(\"Cannot open camera\")\n",
    "            exit()\n",
    "\n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cam.read()\n",
    "            # w = frame.shape[1]\n",
    "            # h = frame.shape[0]\n",
    "            # scale = 224 / w if w < h else 224 / h\n",
    "            # print(\"w: {}, h:{}, scale:{}\".format(w, h, scale))\n",
    "\n",
    "            # if frame is read correctly ret is True\n",
    "            if not ret:\n",
    "                print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "                break\n",
    "        \n",
    "            cv2.imshow('frame', frame)\n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"resize\")\n",
    "        input_size = 224\n",
    "        cam = cv2.VideoCapture(video)\n",
    "\n",
    "        ret_val, orig_frame = cam.read()\n",
    "        w = orig_frame.shape[1]\n",
    "        h = orig_frame.shape[0]\n",
    "        scale = input_size / w if w < h else input_size / h\n",
    "        # w: 640, h:480, scale:0.4666666666666667\n",
    "        # print(\"w: {}, h:{}, scale:{}\".format(w, h, scale))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        while (cam.isOpened()) and ret_val is True:\n",
    "            tic = time.time()\n",
    "            im = cv2.resize(orig_frame, (0, 0), fx=scale, fy=scale)\n",
    "            new_w = im.shape[1]\n",
    "            new_h = im.shape[0]\n",
    "\n",
    "            if new_w > new_h:\n",
    "                offset = (new_w - input_size) // 2\n",
    "                cropped = im[0: input_size, offset: offset + input_size]\n",
    "            else:\n",
    "                offset = (new_h - input_size) // 2\n",
    "                cropped = im[offset: offset + input_size, 0: input_size]       \n",
    "\n",
    "            ret_val, orig_frame = cam.read()\n",
    "            toc = time.time()\n",
    "            print('fps: {}'.format(1 / (toc - tic)))\n",
    "            # print('Processing frame: ', i)\n",
    "            # print(\"cropped_w: {}, cropped_h: {}\".format(cropped.shape[1], cropped.shape[0]))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            cv2.imshow('frame', cropped)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4386b13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f08184522238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrun_on_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_resize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# main_cap(video=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# pose_cap_save_video(video=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d5253356c3d1>\u001b[0m in \u001b[0;36mtrun_on_camera\u001b[0;34m(video, is_resize)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mret_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # main()\n",
    "    trun_on_camera(video=0, is_resize=True)\n",
    "    # main_cap(video=0)\n",
    "    # pose_cap_save_video(video=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb823d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
